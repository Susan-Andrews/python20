{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "#web scraping is used to extract informations from the website ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Requests library is used for making HTTP requests to a specific URL and returns the response.\n#Python requests provide inbuilt functionalities for managing both the request and response.\n#Python requests module has several built-in methods to make HTTP requests to specified URI using GET, POST, PUT, PATCH, or HEAD requests. A HTTP request is meant to either retrieve data from a specified URI or to push data to a server. \n#It works as a request-response protocol between a client and a server. Here we will be using the GET request. \n#GET method is used to retrieve information from the given server using a given URI.\n#The GET method sends the encoded user information appended to the page request. \n\n\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#BeautifulSoup is used extract information from the HTML and XML files. It provides a parse tree and the functions to navigate, search or modify this parse tree.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Finding Elements\n# The soup object contains all the data in the nested structure which could be programmatically extracted. \n#The website we want to scrape contains a lot of text so now letâ€™s scrape all those content. \n\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}